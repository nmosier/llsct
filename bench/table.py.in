#!${Python3_EXECUTABLE}

import argparse
import sys
import os
import json
import tempfile
import math

parser = argparse.ArgumentParser()
parser.add_argument('tests')
parser.add_argument('-o', dest = 'outpath', required = True, action = 'store')
parser.add_argument('--skip')

args = parser.parse_args()

with open(args.tests) as f:
    spec = json.load(f)

out = open(args.outpath, 'w')

# emit preamble
print('\\begin{tabular}{|c|c|c|c|}\\hline', file = out)
print('Benchmark & Defense & Time & Overhead \\\\\\hline', file = out)

def find_benchmark(benchmarks, size):
    for benchmark in benchmarks:
        suffix = '_mean'
        if size != 0:
            suffix = f'/{size}' + suffix
        if benchmark['name'].endswith(suffix):
            return benchmark
    return None

# benchmark flags
benchmark_flags = spec['benchmark_flags']
def run_benchmark(exe, outpath):
    args = [exe, f'--benchmark_out={outpath}', '--benchmark_out_format=json', *benchmark_flags]
    cmd = ' '.join(args)
    print(f'Running: {cmd}', file = sys.stderr)
    if os.system(' '.join(args)) != 0:
        print('benchmark failed: ', args, file = sys.stderr)
        exit(1)

# emit entries
defenses = None
overheads = []
for i in range(4):
    overheads.append([])
for bench in spec['benchmarks']:
    # run experiments
    results = []
    if defenses is None:
        defenses = [defense['name'] for defense in bench['defenses']]
    for defense in bench['defenses']:
        jfd, jpath = tempfile.mkstemp(text = True)
        args = [
            defense['bin'],
            f'--benchmark_out={jpath}',
            '--benchmark_out_format=json',
            '--benchmark_repetitions=5',
            '--benchmark_min_warmup_time=1',
        ]
        run_benchmark(defense['bin'], jpath)
        with os.fdopen(jfd, 'r') as jfile:
            j = json.load(jfile)
        results.append(j)

    for size in bench['sizes']:
        size = int(size)
        baseline_time = None
        for i, defense in enumerate(bench['defenses']):
            j = results[i]
            result = find_benchmark(j['benchmarks'], size)
            assert result
            time = float(result['cpu_time'])
            if baseline_time is None:
                baseline_time = time
            overhead = (time / baseline_time - 1) * 100
            overheads[i].append(time / baseline_time)
            
            # generate table entry
            if i == 0:
                print('\\multirow{4}*{%s%s}' % (bench['name'], '' if size == 0 else ' (%d %s)' % (int(size), bench['sizeunit'])), file = out, end = '')
                 #print('\\multirow{4}*{' + bench['name'] + '}', file = out, end = '')
            print(' & %s & %.2f %s & %.1f\\%% \\\\' % (defense['name'], time, result['time_unit'], overhead), file = out, end = '')
            print('\\hline' if i == 3 else '\\cline{2-4}', file = out)
        

# Geometric means
geomeans = [math.prod(l) ** (1.0 / len(l)) for l in overheads]
for i, geomean in enumerate(geomeans):
    overhead = (geomean - 1) * 100
    if i == 0:
        print('\\multirow{4}*{Geometric means}', file = out, end = '')
    print(' & %s & & %.1f\\%% \\\\' % (defenses[i], overhead), file = out)
    print('\\hline' if i == 3 else '\\cline{2-4}', file = out)
            
# emit epilogue
print('\\end{tabular}', file = out)

